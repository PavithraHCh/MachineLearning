{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010261e4-4801-4c37-920e-027e0cb3e768",
   "metadata": {},
   "source": [
    "# GENERATING NEW SAMPLES AND ANOMALY DETECTION USING GAUSSIAN MIXTURE MODEL\n",
    "_**Develop a program to train a Gaussian mixture model on an appropriate dataset and use the model to generate new samples, visualize them and perform anomaly detection.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e0412-9a29-4427-a0a1-eec4c3abf7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043b161-9e3a-42dd-828d-40a12459629d",
   "metadata": {},
   "source": [
    "## Retrieval & Preparation of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1cd448-490c-4907-ad77-639195e3b3c9",
   "metadata": {},
   "source": [
    "This experiment uses the same Olivetti faces dataset that the other experiment _**CLUSTERING USING K-MEANS ALGORITHM**_  used. You may get the details of the dataset from the respective section of that experiment available in notebook `P3_k-means_clustering.ipynb` stored in the same folder in this repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc939cd0-9567-49f8-867d-822a840f7d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downloads Olivetti faces dataset\n",
    "\n",
    "# NOTE: Downloading this data for the first time will several seconds to complete\n",
    "olivetti = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493675bd-617f-4a59-81fb-5197144453dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checks the shape of the dataset\n",
    "print(olivetti.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c18ec8-3357-466b-afd9-a5897868f271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splits dataset into train and test set containing 90% and 10% instances, respectively.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    olivetti.data, olivetti.target, test_size=0.10, random_state=42, stratify=olivetti.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdfad3-875d-4ef0-92ba-2a94ab500d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Further seperates around 20% (80) of the instances from train set as validation set.\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=80, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46eb58c-b530-4e59-beeb-f10e4f574d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prints the shape of training, validation and test dataset.\n",
    "print(\"Shape of train dataset:\", X_train.shape)\n",
    "print(\"Shape of validation dataset:\", X_val.shape)\n",
    "print(\"Shape of test dataset:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa1e26-f159-407f-9aa8-e3a1119bd52b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reducing Dimensionality of the Datasets to Speed-up Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62c2d8-8893-4198-8414-0b24e1ecb91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates PCA instance to analyze principal components of data set such that these can explain 99% of variance of the data.\n",
    "pca = PCA(n_components=0.99)\n",
    "\n",
    "# Fits the principal component analyzer on the train set\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Gets the reduced dataset for train, validation and test set\n",
    "X_train_reduced = pca.transform(X_train)\n",
    "X_val_reduced = pca.transform(X_val)\n",
    "X_val_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e7f85-f5c9-4fdb-b1d1-a9ae478a6c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checks the number of principal components\n",
    "print(\"Number of principal components: \", pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11861d8-94e7-4ffe-95b0-9cc2a6a8fca1",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f827cdd-089c-4ed2-8563-2700905ad776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Gaussian mixture model on reduced Olivetti faces dataset\n",
    "\n",
    "gaussian_mixture = GaussianMixture(n_components=40, random_state=42)\n",
    "\n",
    "gaussian_mixture.fit(X_train_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaffff4-2943-4cc6-b658-616bdd8f6d96",
   "metadata": {},
   "source": [
    "## Generating New Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902de76-c299-4238-b5ee-2999317084a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates 50 new faces\n",
    "\n",
    "generated_faces_reduced, generated_faces_labels = gaussian_mixture.sample(n_samples=50)\n",
    "\n",
    "# The above method returns a tuple first element of which holds the samples of newly generated faces,\n",
    "# and the other element holds the labels (cluster ID) that each new sample belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a4289-206e-4dac-bbbf-d1e655585fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, PCA was used to reduce the dimensionality before passing the dataset into the algorithm,\n",
    "# the dimension of the generated faces will the same as that of the reduced dataset that was\n",
    "# passed-in for modeling. Hence, to visualize the generated faces, the dimensionality of the \n",
    "# generated faces gets restored.\n",
    "\n",
    "generated_faces = pca.inverse_transform(generated_faces_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ca421-5185-4e89-ad9d-17bda8988fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checks the shape after restoration\n",
    "print(generated_faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef13fc-e250-4215-be8c-dcb038eb0363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_faces(faces, labels, n_cols=10):\n",
    "    \"\"\"\n",
    "    Helper function to plot the faces.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    faces : 2-D array-like\n",
    "        One or more faces across rows where each row represents a face\n",
    "        \n",
    "    labels : 1d array-like\n",
    "        Ground truth (correct) labels.\n",
    "        \n",
    "    n_cols : int, default=10\n",
    "        Numer of columns to be used to plot faces. It is maxium number of faces to be plotted in a row.\n",
    "    \"\"\"\n",
    "    \n",
    "    faces = faces.reshape(-1, 64, 64)  # Reshapes from one to two dimensions to make image plotting easy\n",
    "    \n",
    "    # Calculates number of rows requires to print all faces in cluster when maximum number of columns is n_cols\n",
    "    n_rows = (len(faces) - 1) // n_cols + 1  \n",
    "    \n",
    "    plt.figure(figsize=(n_cols, n_rows))   # Configures the figure size as required\n",
    "    \n",
    "    # Iterates over all faces with labels\n",
    "    for index, (face, label) in enumerate(zip(faces, labels)):\n",
    "        # References subplots in a figure and selects a subplot indicates by 3rd parameter (1-based index)\n",
    "        plt.subplot(n_rows, n_cols, index+1)\n",
    "        \n",
    "        plt.imshow(face, cmap=\"gray\")  # Shows the face in the plot selected in the previous step        \n",
    "        plt.axis(\"off\")                # Axes are made off for asthetics\n",
    "        plt.title(label)               # Writes face's origial label as title of the selected plot\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d9c5a-a316-49f2-83b0-6c107022cb73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_faces(generated_faces, generated_faces_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe18a4-0b10-41bd-bb7c-5bd2aa93d3f4",
   "metadata": {},
   "source": [
    "## Detecting Anomalies\n",
    "Gaussian mixture model considers an instance an anomaly if it is located in low-density region in a cluster. The greater the score, the higher the sensity and lesser chance of that being an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a508b2-28ca-4ce9-91b0-fb420ad6758b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b7bbd-5559-43e2-95bf-7a6cf91a0901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train[:4].reshape(-1, 64, 64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0dced8-8835-48d5-9251-767aa01aabae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.transpose(X_train[:4].reshape(-1, 64, 64), axes=[0, 2, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96dca9b-685d-4614-8d92-d0f014eff929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, let's creates few faces (by modifying the existing ones) and checks if the model\n",
    "# considers these as anomalies.\n",
    "\n",
    "# Rotates 4 faces\n",
    "n_rotated = 4\n",
    "rotated_faces = np.transpose(\n",
    "    X_train[:n_rotated].reshape(-1, 64, 64),           # Reshapes selected faces into 2-dimensional\n",
    "    axes=[0, 2, 1]                                     # Last two axes will be interchanged to transpose\n",
    ")\n",
    "rotated_faces = rotated_faces.reshape(-1, 64*64)             # Flattens back the rotated faces \n",
    "y_rotated_faces = y_train[:n_rotated]                  # Gets the actual target/labels of the faces for later reference\n",
    "\n",
    "# Flips 3 faces\n",
    "n_flipped = 3\n",
    "flipped_faces = X_train[:n_flipped].reshape(-1, 64, 64)[:, ::-1]  # Pixels 2-dimensional faces get flipped vertically for all columns\n",
    "flipped_faces = flipped_faces.reshape(-1, 64*64)                        # Flattens back the flipped faces\n",
    "y_flipped_faces = y_train[:n_flipped]                             # Gets the actual target/labels of the faces for later reference\n",
    "\n",
    "n_darkened = 3\n",
    "darkened_faces = X_train[:n_darkened].copy()           # Gets copies first before pixel manipulation\n",
    "darkened_faces[:, 1:-1] *= 0.2                         # Reduces the pixel intensities by 80%\n",
    "y_darkened_faces = y_train[:n_darkened]                # Gets the actual target/labels of the faces for later reference\n",
    "\n",
    "X_modified_faces = np.r_[rotated_faces, flipped_faces, darkened_faces] # Joins the flattened sequences of 1-D arrays of faces along the row axis.\n",
    "y_modified_faces = np.concatenate(\n",
    "    [y_rotated_faces, y_flipped_faces, y_darkened_faces])              # Joins a sequence of 1-D arrays of face labels along an existing axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c671ed-6842-4416-a425-a9081141786c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Shape of rotated_faces\", rotated_faces.shape)\n",
    "print(\"Shape of flipped_faces\", flipped_faces.shape)\n",
    "print(\"Shape of darkened_faces\", darkened_faces.shape)\n",
    "print(\"Shape of X_modified_faces\", X_modified_faces.shape)\n",
    "print(\"Shape of y_modified_faces\", y_modified_faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0d77b-2d99-4c24-aae0-ee79cd393563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plots the modified faces\n",
    "plot_faces(X_modified_faces, y_modified_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc5f56-aa88-45ee-86a9-6b1dce73d92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gets the reduced dataset for the modified faces\n",
    "X_modified_faces_reduced = pca.transform(X_modified_faces)\n",
    "\n",
    "# Prints the new shape\n",
    "print(X_modified_faces_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de6aae-dde3-44e1-a6f5-f59a372f7fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model calculates the log of probability density estimate (PDF) for each given instance\n",
    "log_pdf_modified_faces = gaussian_mixture.score_samples(X_modified_faces_reduced)\n",
    "\n",
    "print(\"Scores of the modified faces:\", log_pdf_modified_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08965a-4f3d-4016-8f61-b3d40454326a",
   "metadata": {},
   "source": [
    "These negative numbers indicate that these instances are predicted to be located at low-density region and hence can be considered as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b75ef1-198c-4b5b-bbf3-db9f7f3f2778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, let's compare the scores for few of the training instances\n",
    "print(gaussian_mixture.score_samples(X_train_reduced[:10]).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489fb31-17ad-4702-af70-8fb559af7797",
   "metadata": {},
   "source": [
    "These are positive indicating these are to be located at the high-density region in respective cluster and are highly unlikely to be anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7561e-ec9c-4f8f-a273-29d9ca832dce",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "1. Gaussian mixture is a generative model capable of generating new samples from multiple distribution it has learned.\n",
    "2. It can be used to detect anomalies by scoring the samples and checking if these indicates samples' location in low-density region making them highly likely to be anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6eafdf-cfbf-4baf-af2c-37736a308be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
